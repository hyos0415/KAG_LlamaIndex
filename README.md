# 매일경제 뉴스 수집 (ETL) 프로젝트

이 프로젝트는 매일경제 RSS 피드에서 뉴스 기사 목록을 가져와 본문을 크롤링하고, Airflow를 통해 매시간 자동으로 데이터를 수집하는 배치 서빙 시스템입니다.

## 🚀 주요 기능
- **RSS 뉴스 수집**: 매일경제 최신 뉴스 목록 및 발행 시간 수집
- **본문 정제**: HTML 태그 및 광고 요소를 제거한 깨끗한 본문 텍스트 추출
- **자동화 (Airflow)**: 매시간 수집 작업을 자동으로 실행하는 스케줄링 시스템
- **컨테이너화 (Docker)**: 복잡한 설치 없이 도커만으로 모든 환경 구축

## 🛠 필수 요구 사항
- **[Docker Desktop](https://www.docker.com/products/docker-desktop/)**이 설치되어 있고 실행 중이어야 합니다.

## 🏃 실행 방법

### 1. 시스템 시작
터미널에서 프로젝트 루트 폴더로 이동한 뒤 아래 명령어를 입력하세요:
```bash
docker-compose up -d
```
*`-d` 옵션은 백그라운드에서 실행함을 의미합니다.*

### 2. 에어플로우 접속 및 로그인
브라우저를 열고 다음 주소에 접속합니다:
- **URL**: [http://localhost:8080](http://localhost:8080)
- **ID**: `airflow`
- **Password**: `airflow`

### 3. 수집 시작 (DAG 활성화)
웹 화면의 **DAGs** 리스트에서 `mk_news_extraction` 왼쪽의 스위치를 클릭하여 **파란색(Unpaused)**으로 바꾸면 수집이 즉시/정기적으로 시작됩니다.

## 📂 폴더 구조 및 결과물
- **`ETL_expr/`**: 뉴스 소스코드 (`news_extract.py`)
- **`dags/`**: 에어플로우 작업 명세서
- **`result/airflow/`**: **뉴스가 저장되는 곳!** (`mk_news_yyyyMMdd_HHmm.json` 형태)
- **`logs/`**: 실행 기록 일지

## 🛑 중지 및 관리

- **자동 실행 일시 정지**: 에어플로우 웹 화면에서 DAG 스위치를 끕니다.
- **시스템 전체 종료**: 터미널에서 아래 명령어를 사용합니다.
  ```bash
  docker-compose down
  ```

## 📝 참고 사항
- 도커 실행 중 한글 로그가 깨져 보일 경우, 환경 변수(`LANG=C.UTF-8`) 설정을 통해 해결되어 있습니다.
- 수집된 데이터는 `.gitignore` 설정에 따라 Git 커밋에서 제외됩니다.