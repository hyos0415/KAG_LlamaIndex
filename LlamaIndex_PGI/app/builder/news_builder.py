import os
import json
from typing import List, Optional
from llama_index.llms.anthropic import Anthropic
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.core import Document, PropertyGraphIndex, Settings, StorageContext, load_index_from_storage
from llama_index.core.indices.property_graph import SimpleLLMPathExtractor

class ClaudeNewsBuilder:
    def __init__(self, model_name: str = "claude-sonnet-4-0", storage_dir: str = "./storage_claude"):
        """
        Claude ê¸°ë°˜ ë‰´ìŠ¤ ì§€ëŠ¥í˜• ë¹Œë” ì´ˆê¸°í™”
        """
        self.model_name = model_name
        self.storage_dir = storage_dir
        
        # LLM ë° ì„ë² ë”© ì„¤ì •
        self.llm = Anthropic(model=self.model_name, timeout=300.0)
        self.embed_model = OpenAIEmbedding(model="text-embedding-3-small")
        
        # LlamaIndex ì „ì—­ ì„¤ì • ì ìš©
        Settings.llm = self.llm
        Settings.embed_model = self.embed_model
        
        self.index = None

    def load_news_documents(self, file_path: str, limit: Optional[int] = None) -> List[Document]:
        """
        JSON ë‰´ìŠ¤ íŒŒì¼ì—ì„œ ë¬¸ì„œë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
        """
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")

        with open(file_path, 'r', encoding='utf-8') as f:
            news_data = json.load(f)
        
        # ë¦¬ë°‹ ì„¤ì • (ê³µëª¨ì „ í¬ë ˆë”§ ì ˆì•½ìš©)
        if limit:
            news_data = news_data[:limit]
            
        documents = []
        for item in news_data:
            if item.get('content'):
                doc = Document(
                    text=item['content'],
                    metadata={
                        "title": item.get('title', 'N/A'),
                        "url": item.get('url', 'N/A'),
                        "pub_date": item.get('pub_date', 'N/A'),
                        "news_id": item.get('id', 'N/A')
                    }
                )
                documents.append(doc)
        
        print(f"âœ… {len(documents)}ê°œì˜ ë‰´ìŠ¤ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        return documents

    def build_graph(self, documents: List[Document], persist: bool = True):
        """
        ë‰´ìŠ¤ ë¬¸ì„œë“¤ì„ ì§€ì‹ ê·¸ë˜í”„ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        """
        print(f"ğŸš€ '{self.model_name}' ì—”ì§„ì„ ì‚¬ìš©í•˜ì—¬ ì§€ì‹ ì¶”ì¶œì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        # ì¶”ì¶œê¸° ì„¤ì • (ììœ ë„ ë†’ì€ ì§€ì‹ ì¶”ì¶œì„ ìœ„í•´ SimpleLLMPathExtractor ì‚¬ìš©)
        extractor = SimpleLLMPathExtractor(
            llm=self.llm,
            num_workers=2
        )
        
        # ê¸°ì¡´ ì €ì¥ì†Œ ì‚­ì œ (ìƒˆë¡œ êµ¬ì¶• ì‹œ)
        if persist and os.path.exists(self.storage_dir):
            import shutil
            shutil.rmtree(self.storage_dir)
        
        self.index = PropertyGraphIndex.from_documents(
            documents,
            kg_extractors=[extractor],
            show_progress=True
        )
        
        if persist:
            os.makedirs(self.storage_dir, exist_ok=True)
            self.index.storage_context.persist(persist_dir=self.storage_dir)
            print(f"ğŸ’¾ ì§€ì‹ ê·¸ë˜í”„ê°€ '{self.storage_dir}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
        return self.index

    def query(self, query_str: str):
        """
        êµ¬ì¶•ëœ ê·¸ë˜í”„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        """
        if not self.index:
            # ì €ì¥ëœ ì¸ë±ìŠ¤ ë¡œë“œ ì‹œë„
            if os.path.exists(self.storage_dir):
                storage_context = StorageContext.from_defaults(persist_dir=self.storage_dir)
                self.index = load_index_from_storage(storage_context)
            else:
                raise ValueError("êµ¬ì¶•ëœ ì¸ë±ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. build_graphë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
                
        query_engine = self.index.as_query_engine(include_text=True)
        return query_engine.query(query_str)

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë¡œì§
    from dotenv import load_dotenv
    load_dotenv()
    
    builder = ClaudeNewsBuilder()
    
    # 1. ë‰´ìŠ¤ ë°ì´í„° ë”± 1ê°œë§Œ ë¡œë“œ ë° êµ¬ì¶• í…ŒìŠ¤íŠ¸
    data_file = "../result/airflow/mk_news_20260126_1000.json"
    try:
        docs = builder.load_news_documents(data_file, limit=1)
        builder.build_graph(docs)
        
        # 2. ê°„ë‹¨í•œ ê²€ì¦ ì§ˆë¬¸
        res = builder.query("ì´ì¬ìš© íšŒì¥ì˜ ë°©ë¬¸ ëª©ì ì€?")
        print(f"\nğŸ“¢ ì§ˆì˜ ê²°ê³¼: {res}")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
