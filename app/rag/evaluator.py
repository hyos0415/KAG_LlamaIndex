import asyncio
import pandas as pd
from dotenv import load_dotenv
load_dotenv()

from typing import List, Dict, Any
from datasets import Dataset
from ragas import evaluate
from ragas.metrics import (
    faithfulness,
    answer_relevancy,
    context_precision,
    context_recall,
)
from app.rag.langchain_solver import NewsLangChainSolver
from app.etl.storage import StorageManager, NewsArticleModel

class RAGEvaluator:
    def __init__(self, model_name: str = "claude-sonnet-4-0"):
        # ë¡œì„¤ ì‹¤í–‰ì„ ìœ„í•´ DB ê²½ë¡œë¥¼ í˜„ì¬ ë””ë ‰í† ë¦¬ë¡œ ì„¤ì •
        db_path = "sqlite:///news_arena.db"
        self.storage = StorageManager(db_url=db_path)
        self.solver = NewsLangChainSolver(model_name=model_name)
        self.llm = self.solver.llm
        
    async def generate_gold_dataset(self, num_samples: int = 2) -> List[Dict[str, Any]]:
        """
        DBì˜ ì‹¤ì œ ë‰´ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•©ì„± ì§ˆë¬¸(ì‹œí—˜ ë¬¸ì œ) ë° ì •ë‹µì…‹ì„ ìƒì„±í•©ë‹ˆë‹¤.
        """
        print(f"ğŸ§ª {num_samples}ê°œì˜ ë‰´ìŠ¤ë¥¼ ìƒ˜í”Œë§í•˜ì—¬ ê³¨ë“  ë°ì´í„°ì…‹ì„ ìƒì„±í•©ë‹ˆë‹¤...")
        session = self.storage.Session()
        # ìµœì‹  ë‰´ìŠ¤ ì¤‘ ì¼ë¶€ë¥¼ ìƒ˜í”Œë§
        articles = session.query(NewsArticleModel).order_by(NewsArticleModel.id.desc()).limit(num_samples).all()
        
        gold_dataset = []
        for art in articles:
            prompt = (
                f"ë‹¹ì‹ ì€ RAG ì‹œìŠ¤í…œ í‰ê°€ë¥¼ ìœ„í•œ ì‹œí—˜ ì¶œì œ ìœ„ì›ì…ë‹ˆë‹¤.\n"
                f"ì•„ë˜ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ì½ê³ , ì´ ë‰´ìŠ¤ë¥¼ ì°¾ê¸° ìœ„í•´ ì‚¬ìš©ìê°€ ì…ë ¥í–ˆì„ ë²•í•œ 'êµ¬ì²´ì ì¸ ê²€ìƒ‰ ì§ˆë¬¸' í•˜ë‚˜ë§Œ ìƒì„±í•´ì¤˜.\n"
                f"ì¶œë ¥ì€ ì˜¤ì§ ìƒì„±ëœ ì§ˆë¬¸ í…ìŠ¤íŠ¸ë§Œ í•˜ì„¸ìš”.\n\n"
                f"[ëŒ€ìƒ ë‰´ìŠ¤]\nì œëª©: {art.title}\në‚´ìš©: {art.content[:1000]}\n"
            )
            # LangChain Chat ëª¨ë¸ í˜¸ì¶œ
            response = await self.llm.ainvoke(prompt)
            query = response.content.strip()
            
            gold_dataset.append({
                "question": query,
                "ground_truth": art.content,
                "reference_title": art.title
            })
            print(f"  - Q: {query[:50]}...")
            
        session.close()
        return gold_dataset

    async def run_evaluation(self, gold_dataset: List[Dict[str, Any]]):
        """
        ìƒì„±ëœ ê³¨ë“  ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ RAGAS í‰ê°€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        """
        print("\nğŸš€ RAG ë¡œì§ ì‹¤í–‰ ë° ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
        eval_records = []
        
        for item in gold_dataset:
            # 1. RAG ì‹¤í–‰
            result = await self.solver.solve(item["question"])
            
            # 2. RAGAS í¬ë§·ì— ë§ê²Œ ê²°ê³¼ ì¶”ì¶œ
            contexts = [doc.page_content for doc in result["docs"]]
            answer = result["analysis"]
            
            eval_records.append({
                "question": item["question"],
                "answer": answer,
                "contexts": contexts,
                "ground_truth": item["ground_truth"]
            })
            print(f"  - ë‹µë³€ ìƒì„± ì™„ë£Œ: {item['question'][:30]}...")

        # 3. RAGAS í‰ê°€ ìˆ˜í–‰
        dataset = Dataset.from_list(eval_records)
        print("\nğŸ“Š RAGAS ì§€í‘œ ê³„ì‚° ì¤‘...")
        
        # LangChainì˜ ChatAnthropicê³¼ OpenAIEmbeddingsë¥¼ ì§ì ‘ ì „ë‹¬
        # RAGAS 0.1.x ë²„ì „ì—ì„œëŠ” llmê³¼ embeddings ì¸ìë¥¼ ì§ì ‘ ë°›ì„ ìˆ˜ ìˆìŒ
        results = evaluate(
            dataset,
            metrics=[
                faithfulness,
                answer_relevancy,
                context_precision,
                context_recall,
            ],
            llm=self.llm,
            embeddings=self.solver.storage_manager.get_hybrid_retriever().dense_retriever.vectorstore.embeddings
        )
        
        return results

if __name__ == "__main__":
    async def main():
        evaluator = RAGEvaluator()
        gold_data = await evaluator.generate_gold_dataset(num_samples=2)
        eval_results = await evaluator.run_evaluation(gold_data)
        
        print("\n" + "="*50)
        print("ğŸ“Š [RAG Baseline] ì •ëŸ‰ í‰ê°€ ê²°ê³¼ ìš”ì•½")
        print("="*50)
        print(eval_results)
        
        print("\n" + "-"*50)
        print("ğŸ’¡ [ë¶„ì„ ê°€ì´ë“œ]")
        print("1. í˜„ì¬ í‰ê°€ëŠ” 'ê·¸ë˜í”„ ì¶”ë¡ (PGI)' ì´ì „ì˜ 'ìˆœìˆ˜ RAG' ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤.")
        print("2. ì í•©í•œ ë¬¸ì„œë¥¼ ì˜ ì°¾ì•˜ëŠ”ì§€ ë³´ë ¤ë©´ 'context_precision'ì´ ê°€ì¥ ì¤‘ìš”í•©ë‹ˆë‹¤.")
        print("3. ë‚˜ë¨¸ì§€ ì§€í‘œ(faithfulness ë“±)ëŠ” ì§€ì‹ ê·¸ë˜í”„ë¥¼ ê±°ì¹œ ìµœì¢… ë¦¬í¬íŠ¸ ë‹¨ê³„ì—ì„œ ë” í° ì˜ë¯¸ë¥¼ ê°–ìŠµë‹ˆë‹¤.")
        print("="*50)
        
        # ê²°ê³¼ ì €ì¥
        df = eval_results.to_pandas()
        df.to_csv("rag_eval_results.csv", index=False)
        print(f"\nâœ… ë°ì´í„°ì…‹ ìƒì„¸ ê²°ê³¼ê°€ rag_eval_results.csvì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    asyncio.run(main())
